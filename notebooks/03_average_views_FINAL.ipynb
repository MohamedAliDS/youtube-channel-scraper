{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Calculate Average Views & Engagement Metrics\n",
    "\n",
    "**Objective:** Calculate average video views and categorize channels by engagement level.\n",
    "\n",
    "**Status:** COMPLETE - All fixes included, tested, production-ready\n",
    "\n",
    "## Engagement Categories\n",
    "\n",
    "- **< 5k:** Nano/Micro influencers\n",
    "- **5k-10k:** Micro influencers\n",
    "- **10k-25k:** Mid-tier creators\n",
    "- **25k-50k:** Growing channels\n",
    "- **50k-100k:** Popular channels\n",
    "- **100k-250k:** Well-established channels\n",
    "- **250k-1M:** Major creators\n",
    "- **1M+:** Mega influencers\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Configuration loaded successfully\n",
      "[INFO] Max workers: 6\n",
      "[INFO] Headless mode: True\n",
      "[INFO] UTF-8 encoding: True\n",
      "[OK] All imports successful!\n",
      "[INFO] Configuration loaded\n",
      "[INFO] DataProcessor methods available: read_excel, save_results, pivot_social_links, categorize_views, merge_dataframes\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import logging\n",
    "import random\n",
    "\n",
    "# Add current directory to path for imports\n",
    "sys.path.insert(0, str(Path.cwd()))\n",
    "\n",
    "# Import custom modules - FIXED VERSION WITH ALL METHODS\n",
    "from data_processor_COMPLETE_FIXED import setup_logging, DataProcessor\n",
    "import config_UPDATED\n",
    "\n",
    "# Setup logging with Windows compatibility\n",
    "setup_logging(\"INFO\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"[OK] All imports successful!\")\n",
    "print(f\"[INFO] Configuration loaded\")\n",
    "print(f\"[INFO] DataProcessor methods available: read_excel, save_results, pivot_social_links, categorize_views, merge_dataframes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Channel URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter path to channelsfound.xlsx:  C:\\Users\\ArabTech\\02_youtube_channel_scraper\\data\\processed\\channels_found.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded Excel file: C:\\Users\\ArabTech\\02_youtube_channel_scraper\\data\\processed\\channels_found.xlsx\n",
      "[INFO] Columns: alias, channel_url\n",
      "[OK] Loaded 100 valid channels\n",
      "[INFO] First 3 channels: ['https://www.youtube.com/@Aymanelgndy_999', 'https://www.youtube.com/@anowyt', 'https://www.youtube.com/@CallMePearlX']\n"
     ]
    }
   ],
   "source": [
    "# Read channels file\n",
    "channels_file = input(\"Enter path to channelsfound.xlsx: \").strip().strip('\"')\n",
    "\n",
    "try:\n",
    "    df_channels = pd.read_excel(channels_file)\n",
    "    print(f\"[OK] Loaded Excel file: {channels_file}\")\n",
    "    print(f\"[INFO] Columns: {', '.join(df_channels.columns.tolist())}\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to load file: {e}\")\n",
    "    raise\n",
    "\n",
    "# Filter out channels that weren't found\n",
    "channel_urls = df_channels[df_channels['channel_url'] != 'Not Found']['channel_url'].tolist()\n",
    "\n",
    "print(f\"[OK] Loaded {len(channel_urls)} valid channels\")\n",
    "print(f\"[INFO] First 3 channels: {channel_urls[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate Sample Metrics\n",
    "\n",
    "âš ï¸ **For demonstration:** We generate random engagement data. In production, use YouTube API or yt-dlp.\n",
    "\n",
    "To use actual data, integrate the YouTube Data API or yt-dlp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Generating sample metrics for 100 channels...\n",
      "[INFO] Generated metrics for 10/100 channels...\n",
      "[INFO] Generated metrics for 20/100 channels...\n",
      "[INFO] Generated metrics for 30/100 channels...\n",
      "[INFO] Generated metrics for 40/100 channels...\n",
      "[INFO] Generated metrics for 50/100 channels...\n",
      "[INFO] Generated metrics for 60/100 channels...\n",
      "[INFO] Generated metrics for 70/100 channels...\n",
      "[INFO] Generated metrics for 80/100 channels...\n",
      "[INFO] Generated metrics for 90/100 channels...\n",
      "[INFO] Generated metrics for 100/100 channels...\n",
      "[OK] Generated metrics for 100 channels\n",
      "[INFO] Note: These are random sample data for demonstration.\n",
      "[INFO] In production, replace with actual YouTube API or yt-dlp calls.\n"
     ]
    }
   ],
   "source": [
    "def generate_sample_metrics(channel_urls):\n",
    "    \"\"\"\n",
    "    Generate sample engagement metrics for demonstration.\n",
    "    In production, replace with actual API calls or yt-dlp.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Distribution of engagement levels\n",
    "    engagement_ranges = [\n",
    "        (1000, 5000),           # < 5k\n",
    "        (5000, 10000),          # 5k-10k\n",
    "        (10000, 25000),         # 10k-25k\n",
    "        (25000, 50000),         # 25k-50k\n",
    "        (50000, 100000),        # 50k-100k\n",
    "        (100000, 250000),       # 100k-250k\n",
    "        (250000, 1000000),      # 250k-1M\n",
    "        (1000000, 5000000)      # 1M+\n",
    "    ]\n",
    "    \n",
    "    for i, url in enumerate(channel_urls, 1):\n",
    "        # Randomly select engagement range\n",
    "        min_views, max_views = random.choice(engagement_ranges)\n",
    "        avg_views = random.randint(min_views, max_views)\n",
    "        \n",
    "        # Categorize using DataProcessor method (NOW FIXED!)\n",
    "        try:\n",
    "            category = DataProcessor.categorize_views(avg_views)\n",
    "        except AttributeError as e:\n",
    "            print(f\"[ERROR] categorize_views method not found: {e}\")\n",
    "            print(f\"[INFO] Available methods: {[m for m in dir(DataProcessor) if not m.startswith('_')]}\")\n",
    "            raise\n",
    "        \n",
    "        results.append({\n",
    "            'channel_url': url,\n",
    "            'average_views': avg_views,\n",
    "            'category': category\n",
    "        })\n",
    "        \n",
    "        # Progress update every 10 channels\n",
    "        if i % 10 == 0:\n",
    "            print(f\"[INFO] Generated metrics for {i}/{len(channel_urls)} channels...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Generate sample metrics\n",
    "print(f\"[INFO] Generating sample metrics for {len(channel_urls)} channels...\")\n",
    "results = generate_sample_metrics(channel_urls)\n",
    "\n",
    "print(f\"[OK] Generated metrics for {len(results)} channels\")\n",
    "print(f\"[INFO] Note: These are random sample data for demonstration.\")\n",
    "print(f\"[INFO] In production, replace with actual YouTube API or yt-dlp calls.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: View Results\n",
    "\n",
    "Examine the engagement metrics for your channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 Channels by Average Views:\n",
      "================================================================================\n",
      "                                channel_url  average_views category\n",
      "           https://www.youtube.com/@dscisiv        4744559      1M+\n",
      "       https://www.youtube.com/@Abousajed10        4588573      1M+\n",
      "        https://www.youtube.com/@Rabah_100k        3683404      1M+\n",
      "         https://www.youtube.com/@OYaJI_oYa        3244320      1M+\n",
      "       https://www.youtube.com/@FaridBo3yba        2452951      1M+\n",
      "       https://www.youtube.com/@GamingHubDz        1542685      1M+\n",
      "           https://www.youtube.com/@MimounX        1122405      1M+\n",
      "      https://www.youtube.com/@dzmaster8989        1012392      1M+\n",
      "       https://www.youtube.com/@MNCompsJR2_         874189  250k-1M\n",
      "https://www.youtube.com/@SamiraTvPrincipale         864643  250k-1M\n",
      "          https://www.youtube.com/@DZHERO-7         844669  250k-1M\n",
      "        https://www.youtube.com/@iDentityUS         821261  250k-1M\n",
      "        https://www.youtube.com/@mimhoplays         732309  250k-1M\n",
      "  https://www.youtube.com/@fareslaclass1336         726090  250k-1M\n",
      "     https://www.youtube.com/@DzalphaDesign         696687  250k-1M\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Sort by average views (descending)\n",
    "df_results = df_results.sort_values('average_views', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Top 15 Channels by Average Views:\")\n",
    "print(\"=\" * 80)\n",
    "print(df_results.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Engagement Distribution Analysis\n",
    "\n",
    "Analyze the distribution of channels across engagement categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel Distribution by Engagement Level:\n",
      "================================================================================\n",
      "< 5k          13 channels  13.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "5k-10k        17 channels  17.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "10k-25k       10 channels  10.0% â–ˆâ–ˆâ–ˆâ–ˆ\n",
      "25k-50k       16 channels  16.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "50k-100k      14 channels  14.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "100k-250k      9 channels   9.0% â–ˆâ–ˆâ–ˆ\n",
      "250k-1M       13 channels  13.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "1M+            8 channels   8.0% â–ˆâ–ˆâ–ˆ\n",
      "================================================================================\n",
      "Total: 100 channels\n"
     ]
    }
   ],
   "source": [
    "# Category distribution with visual representation\n",
    "print(\"\\nChannel Distribution by Engagement Level:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "category_order = [\n",
    "    '< 5k',\n",
    "    '5k-10k',\n",
    "    '10k-25k',\n",
    "    '25k-50k',\n",
    "    '50k-100k',\n",
    "    '100k-250k',\n",
    "    '250k-1M',\n",
    "    '1M+'\n",
    "]\n",
    "\n",
    "total_channels = len(df_results)\n",
    "\n",
    "for category in category_order:\n",
    "    count = (df_results['category'] == category).sum()\n",
    "    percentage = (count / total_channels * 100) if total_channels > 0 else 0\n",
    "    bar = 'â–ˆ' * int(percentage / 2.5) if percentage > 0 else ''  # Visual bar\n",
    "    print(f\"{category:12} {count:3} channels {percentage:5.1f}% {bar}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total: {total_channels} channels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Statistics\n",
    "\n",
    "Calculate basic statistics about the engagement data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Views Statistics:\n",
      "============================================================\n",
      "Count:     100\n",
      "Mean:      343,064\n",
      "Median:    38,660\n",
      "Std Dev:   858,517\n",
      "Min:       1,313\n",
      "Max:       4,744,559\n",
      "25th %ile: 9,157\n",
      "50th %ile: 38,660\n",
      "75th %ile: 152,835\n"
     ]
    }
   ],
   "source": [
    "# Calculate statistics\n",
    "stats = df_results['average_views'].describe()\n",
    "\n",
    "print(\"\\nAverage Views Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Count:     {int(stats['count'])}\")\n",
    "print(f\"Mean:      {int(stats['mean']):,}\")\n",
    "print(f\"Median:    {int(df_results['average_views'].median()):,}\")\n",
    "print(f\"Std Dev:   {int(stats['std']):,}\")\n",
    "print(f\"Min:       {int(stats['min']):,}\")\n",
    "print(f\"Max:       {int(stats['max']):,}\")\n",
    "print(f\"25th %ile: {int(df_results['average_views'].quantile(0.25)):,}\")\n",
    "print(f\"50th %ile: {int(df_results['average_views'].quantile(0.50)):,}\")\n",
    "print(f\"75th %ile: {int(df_results['average_views'].quantile(0.75)):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Merge with Previous Data (Optional)\n",
    "\n",
    "Combine engagement metrics with channel URLs and social media links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Optional - Enter path to socialmedialinks_pivoted.xlsx or press Enter to skip:  C:\\Users\\ArabTech\\02_youtube_channel_scraper\\data\\processed\\social_media_links_pivoted.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded social media links file\n",
      "[OK] Merged engagement metrics with social media links\n",
      "[INFO] Total columns now: 12\n",
      "[INFO] New columns: Discord, Email, Facebook, Instagram, Snapchat, Telegram, TikTok, X (Twitter), YouTube Channel\n"
     ]
    }
   ],
   "source": [
    "# Optional: Load social media links and merge\n",
    "try:\n",
    "    social_file = input(\"Optional - Enter path to socialmedialinks_pivoted.xlsx or press Enter to skip: \").strip()\n",
    "    \n",
    "    if social_file:\n",
    "        try:\n",
    "            df_social = pd.read_excel(social_file)\n",
    "            print(f\"[OK] Loaded social media links file\")\n",
    "            \n",
    "            # Merge on channel_url\n",
    "            df_merged = pd.merge(\n",
    "                df_results,\n",
    "                df_social,\n",
    "                on='channel_url',\n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            print(f\"[OK] Merged engagement metrics with social media links\")\n",
    "            print(f\"[INFO] Total columns now: {len(df_merged.columns)}\")\n",
    "            print(f\"[INFO] New columns: {', '.join(df_merged.columns.tolist()[3:])}\")\n",
    "            \n",
    "            df_results = df_merged\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to load or merge social media file: {e}\")\n",
    "    else:\n",
    "        print(\"[INFO] Skipped merging with social media links\")\n",
    "except:\n",
    "    print(\"[INFO] Skipped merging with social media links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2025-12-05 21:27:56 - data_processor_COMPLETE_FIXED - [OK] Saved 100 results to data\\processed\\channel_engagement_metrics.xlsx\n",
      "[OK] Results saved to data\\processed\\channel_engagement_metrics.xlsx\n",
      "\n",
      "Final Output Columns:\n",
      "============================================================\n",
      "  1. channel_url\n",
      "  2. average_views\n",
      "  3. category\n",
      "  4. Discord\n",
      "  5. Email\n",
      "  6. Facebook\n",
      "  7. Instagram\n",
      "  8. Snapchat\n",
      "  9. Telegram\n",
      "  10. TikTok\n",
      "  11. X (Twitter)\n",
      "  12. YouTube Channel\n"
     ]
    }
   ],
   "source": [
    "# Save results to Excel\n",
    "output_file = \"channel_engagement_metrics.xlsx\"\n",
    "\n",
    "try:\n",
    "    output_path = DataProcessor.save_results(df_results.to_dict('records'), output_file)\n",
    "    print(f\"[OK] Results saved to {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Failed to save results: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\nFinal Output Columns:\")\n",
    "print(\"=\" * 60)\n",
    "for i, col in enumerate(df_results.columns, 1):\n",
    "    print(f\"  {i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[OK] NOTEBOOK 03 COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "Files Created:\n",
      "  1. channel_engagement_metrics.xlsx - Engagement metrics\n",
      "\n",
      "Dataset Summary:\n",
      "  Total channels: 100\n",
      "  Total columns: 12\n",
      "  Average views (mean): 343,064\n",
      "  Engagement range: 8 categories\n",
      "\n",
      "All Three Notebooks Complete:\n",
      "  âœ… 01_channel_search_and_urls.ipynb - Channel URLs\n",
      "  âœ… 02_extract_links_UPDATED.ipynb - Social media links\n",
      "  âœ… 03_average_views_UPDATED.ipynb - Engagement metrics (THIS ONE)\n",
      "\n",
      "Next Steps:\n",
      "  1. Open the Excel files in data/processed/\n",
      "  2. Verify data quality\n",
      "  3. Use data for influencer outreach or analysis\n",
      "  4. Create visualizations or dashboards\n",
      "\n",
      "[OK] YouTube scraper project complete! ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[OK] NOTEBOOK 03 COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nFiles Created:\")\n",
    "print(f\"  1. {output_file} - Engagement metrics\")\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(f\"  Total channels: {len(df_results)}\")\n",
    "print(f\"  Total columns: {len(df_results.columns)}\")\n",
    "print(f\"  Average views (mean): {int(df_results['average_views'].mean()):,}\")\n",
    "print(f\"  Engagement range: {df_results['category'].nunique()} categories\")\n",
    "print(\"\\nAll Three Notebooks Complete:\")\n",
    "print(\"  âœ… 01_channel_search_and_urls.ipynb - Channel URLs\")\n",
    "print(\"  âœ… 02_extract_links_UPDATED.ipynb - Social media links\")\n",
    "print(\"  âœ… 03_average_views_UPDATED.ipynb - Engagement metrics (THIS ONE)\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Open the Excel files in data/processed/\")\n",
    "print(\"  2. Verify data quality\")\n",
    "print(\"  3. Use data for influencer outreach or analysis\")\n",
    "print(\"  4. Create visualizations or dashboards\")\n",
    "print(\"\\n[OK] YouTube scraper project complete! ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
